{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    " # import fuzzywizzy?\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pymongo\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "src_dir = os.path.join(os.getcwd(), '..', '..', 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# helper functions\n",
    "from d02_processing.cleaning_signatures import sorted_signatures\n",
    "from d02_processing.cleaning_signatures import cleaned_signatures\n",
    "from d01_utils.mongo_cursor_creator import mongo_cursor\n",
    "\n",
    "# Load the \"autoreload\" extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '2c/3a, fine texture, normal porosity, medium-to-thick\\nCo wash: Vo5 Extra Body\\nConditioners: Deva One Condition, GVP CB, Loreal Evercurl\\nStylers: Devacurl ArcAngel, KCCC, AG Recoil, Iso Bouncy Creme, Ecostyler Krystal, CCCCL, KCKT\\nLow Poo: Devacurl NoPoo, GTTT\\nHair likes: plopping, diffusing, SMaster\\'s, coconut and argan oil, honey, protein\\n\"What makes a woman unforgettable? Her mind...surrounded by lots of naturally curly hair\"',\n",
       " 'True 3B\\ncoarse, overly porous, normal elasticity, thick\\nOn the long transitioning road...\\nDiscovered Curly: November 24, 2009:toothy3:\\nHates: humectants, protein, rain, wind, humidity, plopping\\nLoves: moisture, ecostyler, sallys conditioning balm\\n\\n:wav:\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       " \"Silence grows\\nMy feelings flow\\nI'm dreaming now\\nOf all the things I know\\n\",\n",
       " \"I've learned that no matter what happens, or how bad it seems today, life does go on, and it will be better tomorrow.\\n\\n3 b/c shoulder length hair. Black-brown color. It's always mistaken for a Jericurl in less enlightened parts of the US.\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the unique signatures from the database\n",
    "sigs_from_cursor = mongo_cursor()\n",
    "sigs_from_cursor[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>curl_pattern</th>\n",
       "      <th>density</th>\n",
       "      <th>porosity</th>\n",
       "      <th>texture</th>\n",
       "      <th>products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2c</td>\n",
       "      <td>thick</td>\n",
       "      <td>normal</td>\n",
       "      <td>fine</td>\n",
       "      <td>to co wash vo5 extra body conditioners deva ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3a</td>\n",
       "      <td>thick</td>\n",
       "      <td>normal</td>\n",
       "      <td>fine</td>\n",
       "      <td>to co wash vo5 extra body conditioners deva ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3b</td>\n",
       "      <td>thick</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>true coarse overly porous normal elasticity on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>thin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>silence grows my feelings flow i m dreaming no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  curl_pattern density porosity texture  \\\n",
       "0          NaN     NaN      NaN     NaN   \n",
       "1           2c   thick   normal    fine   \n",
       "2           3a   thick   normal    fine   \n",
       "3           3b   thick      NaN     NaN   \n",
       "4          NaN    thin      NaN     NaN   \n",
       "\n",
       "                                            products  \n",
       "0                                                     \n",
       "1    to co wash vo5 extra body conditioners deva ...  \n",
       "2    to co wash vo5 extra body conditioners deva ...  \n",
       "3  true coarse overly porous normal elasticity on...  \n",
       "4  silence grows my feelings flow i m dreaming no...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the signatures\n",
    "raw_characteristics_df = sorted_signatures(sigs_from_cursor)\n",
    "raw_characteristics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>curl_pattern</th>\n",
       "      <th>density</th>\n",
       "      <th>porosity</th>\n",
       "      <th>texture</th>\n",
       "      <th>products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2c</td>\n",
       "      <td>thick</td>\n",
       "      <td>normal</td>\n",
       "      <td>fine</td>\n",
       "      <td>to co wash vo5 extra body conditioners deva ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3a</td>\n",
       "      <td>thick</td>\n",
       "      <td>normal</td>\n",
       "      <td>fine</td>\n",
       "      <td>to co wash vo5 extra body conditioners deva ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3b</td>\n",
       "      <td>thick</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>true coarse overly porous normal elasticity on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>thin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>silence grows my feelings flow i m dreaming no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>toothy4 mix toothy4 bc 09 28 12 occasion9 gro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  curl_pattern density porosity texture  \\\n",
       "1           2c   thick   normal    fine   \n",
       "2           3a   thick   normal    fine   \n",
       "3           3b   thick      NaN     NaN   \n",
       "4          NaN    thin      NaN     NaN   \n",
       "9           4a     NaN      NaN     NaN   \n",
       "\n",
       "                                            products  \n",
       "1    to co wash vo5 extra body conditioners deva ...  \n",
       "2    to co wash vo5 extra body conditioners deva ...  \n",
       "3  true coarse overly porous normal elasticity on...  \n",
       "4  silence grows my feelings flow i m dreaming no...  \n",
       "9   toothy4 mix toothy4 bc 09 28 12 occasion9 gro...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df = cleaned_signatures(raw_characteristics_df)\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       curl_catagory\n",
      "count    7405.000000\n",
      "mean        4.342201\n",
      "std         1.686252\n",
      "min         0.000000\n",
      "25%         3.000000\n",
      "50%         4.000000\n",
      "75%         5.000000\n",
      "max         9.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>curl_pattern</th>\n",
       "      <th>density</th>\n",
       "      <th>porosity</th>\n",
       "      <th>texture</th>\n",
       "      <th>products</th>\n",
       "      <th>curl_catagory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2c</td>\n",
       "      <td>thick</td>\n",
       "      <td>normal</td>\n",
       "      <td>fine</td>\n",
       "      <td>to co wash vo5 extra body conditioners deva ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3a</td>\n",
       "      <td>thick</td>\n",
       "      <td>normal</td>\n",
       "      <td>fine</td>\n",
       "      <td>to co wash vo5 extra body conditioners deva ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3b</td>\n",
       "      <td>thick</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>true coarse overly porous normal elasticity on...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>toothy4 mix toothy4 bc 09 28 12 occasion9 gro...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>toothy4 mix toothy4 bc 09 28 12 occasion9 gro...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   curl_pattern density porosity texture  \\\n",
       "1            2c   thick   normal    fine   \n",
       "2            3a   thick   normal    fine   \n",
       "3            3b   thick      NaN     NaN   \n",
       "9            4a     NaN      NaN     NaN   \n",
       "10           3c     NaN      NaN     NaN   \n",
       "\n",
       "                                             products  curl_catagory  \n",
       "1     to co wash vo5 extra body conditioners deva ...              3  \n",
       "2     to co wash vo5 extra body conditioners deva ...              4  \n",
       "3   true coarse overly porous normal elasticity on...              5  \n",
       "9    toothy4 mix toothy4 bc 09 28 12 occasion9 gro...              7  \n",
       "10   toothy4 mix toothy4 bc 09 28 12 occasion9 gro...              6  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a data fram with no nulls in the different characteristics\n",
    "curl_pattern_no_nan_df = cleaned_df[pd.notnull(cleaned_df['curl_pattern'])]\n",
    "curl_pattern_no_nan_df['curl_catagory'] = pd.Categorical(curl_pattern_no_nan_df.curl_pattern)\n",
    "curl_pattern_no_nan_df[\"curl_catagory\"] = curl_pattern_no_nan_df[\"curl_catagory\"].cat.codes\n",
    "print(curl_pattern_no_nan_df.describe())\n",
    "curl_pattern_no_nan_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "curl_pattern       object\n",
       "density            object\n",
       "porosity           object\n",
       "texture            object\n",
       "products           object\n",
       "curl_catagory    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df['curl_catagory'] = pd.Categorical(cleaned_df.curl_pattern)\n",
    "cleaned_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>curl_pattern</th>\n",
       "      <th>density</th>\n",
       "      <th>porosity</th>\n",
       "      <th>texture</th>\n",
       "      <th>products</th>\n",
       "      <th>curl_catagory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2c</td>\n",
       "      <td>thick</td>\n",
       "      <td>normal</td>\n",
       "      <td>fine</td>\n",
       "      <td>to co wash vo5 extra body conditioners deva ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3a</td>\n",
       "      <td>thick</td>\n",
       "      <td>normal</td>\n",
       "      <td>fine</td>\n",
       "      <td>to co wash vo5 extra body conditioners deva ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3b</td>\n",
       "      <td>thick</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>true coarse overly porous normal elasticity on...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>thin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>silence grows my feelings flow i m dreaming no...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>toothy4 mix toothy4 bc 09 28 12 occasion9 gro...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  curl_pattern density porosity texture  \\\n",
       "1           2c   thick   normal    fine   \n",
       "2           3a   thick   normal    fine   \n",
       "3           3b   thick      NaN     NaN   \n",
       "4          NaN    thin      NaN     NaN   \n",
       "9           4a     NaN      NaN     NaN   \n",
       "\n",
       "                                            products  curl_catagory  \n",
       "1    to co wash vo5 extra body conditioners deva ...              3  \n",
       "2    to co wash vo5 extra body conditioners deva ...              4  \n",
       "3  true coarse overly porous normal elasticity on...              5  \n",
       "4  silence grows my feelings flow i m dreaming no...             -1  \n",
       "9   toothy4 mix toothy4 bc 09 28 12 occasion9 gro...              7  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df[\"curl_catagory\"] = cleaned_df[\"curl_catagory\"].cat.codes\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1          to co wash vo5 extra body conditioners deva ...\n",
       "2          to co wash vo5 extra body conditioners deva ...\n",
       "3        true coarse overly porous normal elasticity on...\n",
       "4        silence grows my feelings flow i m dreaming no...\n",
       "9         toothy4 mix toothy4 bc 09 28 12 occasion9 gro...\n",
       "10        toothy4 mix toothy4 bc 09 28 12 occasion9 gro...\n",
       "11        afro i love4 water he my baby daddy is the de...\n",
       "12        afro i love4 water he my baby daddy is the de...\n",
       "13       hair stats i guess  shoulder length tends to f...\n",
       "14       hair stats i guess  shoulder length tends to f...\n",
       "15       bc d 6 5 2010 last relaxed 5 16 2009 mostly pr...\n",
       "16                                             on the side\n",
       "17        sigpic sigpic littlemisscurls shutterfly com ...\n",
       "18        sigpic sigpic with little s thrown in to make...\n",
       "19        sigpic sigpic with little s thrown in to make...\n",
       "20       i k i m a definitely a corkscrew currently on ...\n",
       "21        wavy baby hair low low poo lush karma komba h...\n",
       "23       mostly looser at nape and edges to strands sof...\n",
       "24       averages out at ranges from to very mane n tai...\n",
       "25       averages out at ranges from to very mane n tai...\n",
       "30        mixed with since december 1 2008 currently us...\n",
       "31        mixed with since december 1 2008 currently us...\n",
       "33         normal elasticity halo frizz and a bit on th...\n",
       "35       hair type brunette length midback when wet sha...\n",
       "36       henna head just past bsl in back when curly si...\n",
       "37                                            heatherdawn \n",
       "38                                            heatherdawn \n",
       "39        long to my lower back when pulled straight pu...\n",
       "40        long to my lower back when pulled straight pu...\n",
       "41        and i k aubrey glycogen protein balancing con...\n",
       "                               ...                        \n",
       "10368    leslie started 7 3 05 with some photobucket co...\n",
       "10369    leslie started 7 3 05 with some photobucket co...\n",
       "10371       my curls are now free to be hooray for layers \n",
       "10372     dry red hair currently using devacurl low poo...\n",
       "10373     dry red hair currently using devacurl low poo...\n",
       "10374     locks daily products suave naturals coconut j...\n",
       "10376                          b growing long read my blog\n",
       "10377     sigpic sigpic baby honey caramel hilites now ...\n",
       "10378     sigpic sigpic baby honey caramel hilites now ...\n",
       "10379    hair type low elasticity from curl wizard prot...\n",
       "10380    hair type low elasticity from curl wizard prot...\n",
       "10381     tongue3 god bless for everyone who exalts him...\n",
       "10382     tongue3 god bless for everyone who exalts him...\n",
       "10383    last relaxer 2000 shampoo curls cleansing crea...\n",
       "10384    last relaxer 2000 shampoo curls cleansing crea...\n",
       "10385     newbie wavy hair my hair is wavy and thumbright \n",
       "10386    hair type current length zilch inches umpteent...\n",
       "10387     last relaxer 25 6 2006 big chop 10 11 2007 i ...\n",
       "10388     last relaxer 25 6 2006 big chop 10 11 2007 i ...\n",
       "10389     my blog faded polaroid mod since oct 21 2009 ...\n",
       "10390    naturally light brown formerly black and colou...\n",
       "10391     blonde hair british norwegian it is beyond my...\n",
       "10393     back on sulfates and cones he ttwisted condis...\n",
       "10394     back on sulfates and cones he ttwisted condis...\n",
       "10395     coarse hair with most of the definition on th...\n",
       "10396     coarse hair with most of the definition on th...\n",
       "10397     i ain t no square with my corkscrew hair marc...\n",
       "10398     total pj love5 modified low poo 2 3x a month ...\n",
       "10399    mostly frizz public fotki com pizazz pw buttercup\n",
       "10400    mostly frizz public fotki com pizazz pw buttercup\n",
       "Name: products, Length: 7961, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 4), stop_words='english')\n",
    "features = tfidf.fit_transform(curl_pattern_no_nan_df.products).toarray()\n",
    "labels = curl_pattern_no_nan_df.curl_catagory\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1c': 0, '2a': 1, '2b': 2, '2c': 3, '3a': 4, '3b': 5, '3c': 6, '4a': 7, '4b': 8, '4c': 9}\n",
      "{0: '1c', 1: '2a', 2: '2b', 3: '2c', 4: '3a', 5: '3b', 6: '3c', 7: '4a', 8: '4b', 9: '4c'}\n"
     ]
    }
   ],
   "source": [
    "# df['category_id'] = df['Product'].factorize()[0]\n",
    "# from io import StringIO\n",
    "# category_id_df = df[['Product', 'category_id']].drop_duplicates().sort_values('category_id')\n",
    "# category_to_id = dict(category_id_df.values)\n",
    "# id_to_category = dict(category_id_df[['category_id', 'Product']].values)\n",
    "\n",
    "curl_catagory_df = curl_pattern_no_nan_df[['curl_pattern', 'curl_catagory']].drop_duplicates().sort_values('curl_catagory')\n",
    "curl_cat_key_dict = dict(curl_catagory_df.values)\n",
    "curl_pattern_key_dict = dict(curl_catagory_df[['curl_catagory', 'curl_pattern']].values)\n",
    "print(curl_cat_key_dict)\n",
    "print(curl_pattern_key_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# '1c':\n",
      "  . Most correlated unigrams:\n",
      ". hell\n",
      ". sense\n",
      "  . Most correlated bigrams:\n",
      ". com youtube\n",
      ". shampoo weeks\n",
      "  . Most correlated trigrams:\n",
      ". jessicurl cleansing cream\n",
      ". psalm 139 14\n",
      "  . Most correlated quadgrams:\n",
      ". poo mop hydrating shampoo\n",
      ". tresemme naturals moisturizing conditioner\n",
      "# '2a':\n",
      "  . Most correlated unigrams:\n",
      ". wavy\n",
      ". elephant\n",
      "  . Most correlated bigrams:\n",
      ". canopy underneath\n",
      ". wavy hair\n",
      "  . Most correlated trigrams:\n",
      ". healthy sexy hair\n",
      ". ro ss caitlin\n",
      "  . Most correlated quadgrams:\n",
      ". normal elasticity low poo\n",
      ". la looks mega hold\n",
      "# '2b':\n",
      "  . Most correlated unigrams:\n",
      ". elasticity\n",
      ". wavy\n",
      "  . Most correlated bigrams:\n",
      ". shampoo body\n",
      ". ness low\n",
      "  . Most correlated trigrams:\n",
      ". beauticurls li curl\n",
      ". shampoo body shop\n",
      "  . Most correlated quadgrams:\n",
      ". wash vo5 kiwi lime\n",
      ". yes cucumbers color protection\n",
      "# '2c':\n",
      "  . Most correlated unigrams:\n",
      ". relaxer\n",
      ". coarse\n",
      "  . Most correlated bigrams:\n",
      ". naturals ro\n",
      ". normal elasticity\n",
      "  . Most correlated trigrams:\n",
      ". coarse normal elasticity\n",
      ". curly just wavy\n",
      "  . Most correlated quadgrams:\n",
      ". moisture coconut hibiscus hold\n",
      ". li kinky curly knot\n",
      "# '3a':\n",
      "  . Most correlated unigrams:\n",
      ". bc\n",
      ". relaxer\n",
      "  . Most correlated bigrams:\n",
      ". relaxer free\n",
      ". botticelli curls\n",
      "  . Most correlated trigrams:\n",
      ". just shoulder length\n",
      ". members fotki com\n",
      "  . Most correlated quadgrams:\n",
      ". curly kinks satin roots\n",
      ". giovanni direct leave styling\n",
      "# '3b':\n",
      "  . Most correlated unigrams:\n",
      ". brown\n",
      ". corkscrew\n",
      "  . Most correlated bigrams:\n",
      ". brown curls\n",
      ". shoulders dry\n",
      "  . Most correlated trigrams:\n",
      ". just past shoulders\n",
      ". dark brown curls\n",
      "  . Most correlated quadgrams:\n",
      ". sheamoisture manuka honey mafura\n",
      ". gvp conditioning balm gel\n",
      "# '3c':\n",
      "  . Most correlated unigrams:\n",
      ". transitioning\n",
      ". bc\n",
      "  . Most correlated bigrams:\n",
      ". mommy curly\n",
      ". relaxer free\n",
      "  . Most correlated trigrams:\n",
      ". holy grail products\n",
      ". shoulder length curly\n",
      "  . Most correlated quadgrams:\n",
      ". trader joe nourish conditioner\n",
      ". trader joes nourish spa\n",
      "# '4a':\n",
      "  . Most correlated unigrams:\n",
      ". bc\n",
      ". relaxer\n",
      "  . Most correlated bigrams:\n",
      ". members fotki\n",
      ". fotki com\n",
      "  . Most correlated trigrams:\n",
      ". public fotki com\n",
      ". members fotki com\n",
      "  . Most correlated quadgrams:\n",
      ". fotki members fotki com\n",
      ". youtube channel youtube com\n",
      "# '4b':\n",
      "  . Most correlated unigrams:\n",
      ". afro\n",
      ". relaxer\n",
      "  . Most correlated bigrams:\n",
      ". relaxer november\n",
      ". kinky coily\n",
      "  . Most correlated trigrams:\n",
      ". hair type current\n",
      ". learning love hair\n",
      "  . Most correlated quadgrams:\n",
      ". ultimate goal waist length\n",
      ". hair type current length\n",
      "# '4c':\n",
      "  . Most correlated unigrams:\n",
      ". game\n",
      ". soaps\n",
      "  . Most correlated bigrams:\n",
      ". combo hair\n",
      ". relaxer oct\n",
      "  . Most correlated trigrams:\n",
      ". 2011 big chop\n",
      ". product junkie current\n",
      "  . Most correlated quadgrams:\n",
      ". oil castor oil olive\n",
      ". amla olive heavy cream\n"
     ]
    }
   ],
   "source": [
    "N = 2\n",
    "for curl_pattern, curl_cat in sorted(curl_cat_key_dict.items()):\n",
    "    features_chi2 = chi2(features, labels == curl_cat)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    trigrams = [v for v in feature_names if len(v.split(' ')) == 3]\n",
    "    quadgrams = [v for v in feature_names if len(v.split(' ')) == 4]\n",
    "    print(\"# '{}':\".format(curl_pattern))\n",
    "    print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-N:])))\n",
    "    print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-N:])))\n",
    "    print(\"  . Most correlated trigrams:\\n. {}\".format('\\n. '.join(trigrams[-N:])))\n",
    "    print(\"  . Most correlated quadgrams:\\n. {}\".format('\\n. '.join(quadgrams[-N:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "take_nd() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-4828ad38add5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaned_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'density'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'porosity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'products'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'texture'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaned_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurl_catagory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2123\u001b[0m     return list(chain.from_iterable((safe_indexing(a, train),\n\u001b[0;32m-> 2124\u001b[0;31m                                      safe_indexing(a, test)) for a in arrays))\n\u001b[0m\u001b[1;32m   2125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2123\u001b[0m     return list(chain.from_iterable((safe_indexing(a, train),\n\u001b[0;32m-> 2124\u001b[0;31m                                      safe_indexing(a, test)) for a in arrays))\n\u001b[0m\u001b[1;32m   2125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36msafe_indexing\u001b[0;34m(X, indices)\u001b[0m\n\u001b[1;32m    217\u001b[0m                                    indices.dtype.kind == 'i'):\n\u001b[1;32m    218\u001b[0m             \u001b[0;31m# This is often substantially faster than X[indices]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: take_nd() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "X = cleaned_df[['density', 'porosity', 'products', 'texture']]\n",
    "y = cleaned_df.curl_catagory\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10794"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = np.array(tfidf.get_feature_names())\n",
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
